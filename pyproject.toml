[build-system]
requires = ["setuptools>=61.0"]
build-backend = "setuptools.build_meta"

[project]
name = "llama-omni"
version = "1.0.0"
description = "Towards GPT-4o like large speech-language model."
readme = "README.md"
requires-python = ">=3.10"
classifiers = [
    "Programming Language :: Python :: 3",
    "License :: OSI Approved :: Apache Software License",
]
dependencies = [
    "torch", "torchvision", "torchaudio",
    "transformers", "tokenizers", "sentencepiece", "shortuuid",
    "accelerate", "peft", "bitsandbytes",
    "pydantic", "markdown2[all]", "numpy", "scikit-learn",
    "gradio", "gradio_client",
    "requests", "httpx", "uvicorn", "fastapi", "soundfile",
    "einops", "einops-exts", "timm",
    "openai-whisper", "setuptools", "omegaconf",
]

[project.optional-dependencies]
train = ["deepspeed", "ninja", "wandb", "tensorboardX"]
build = ["build", "twine"]

[tool.setuptools.packages.find]
exclude = ["data", "checkpoints", "logs", "models", "fairseq", "flash-attention"]

[tool.wheel]
exclude = ["data", "checkpoints", "logs", "models", "fairseq", "flash-attention"]
